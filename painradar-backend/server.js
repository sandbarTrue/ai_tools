// PainRadar Backend Server - Spaceship Edition
// è¿è¡Œåœ¨æµ·å¤–æœåŠ¡å™¨ï¼Œç›´æŽ¥è°ƒç”¨å¤–éƒ¨APIï¼Œå­˜MySQLï¼ŒæŽ¨é€Vercel

const http = require('http');
const { execSync } = require('child_process');
const mysql = require('mysql2/promise');

const PORT = 3847;
const DB_CONFIG = {
  host: 'localhost',
  user: 'ztshkzhkyl_radar',
  password: process.env.DB_PASSWORD || 'Pr@dar2026Sec',
  database: 'ztshkzhkyl_painradar',
  charset: 'utf8mb4',
};
const ZHIPU_KEY = process.env.ZHIPU_API_KEY;
const VERCEL_TOKEN = process.env.VERCEL_TOKEN;
const VERCEL_PROJECT_DIR = process.env.VERCEL_PROJECT_DIR;

// ========== Fetch helper (Node 22 built-in fetch) ==========
async function fetchJSON(url, options = {}) {
  const timeout = options.timeout || 30000;
  const controller = new AbortController();
  const timer = setTimeout(() => controller.abort(), timeout);
  try {
    const res = await fetch(url, {
      method: options.method || 'GET',
      headers: options.headers || {},
      body: options.body ? (typeof options.body === 'string' ? options.body : JSON.stringify(options.body)) : undefined,
      signal: controller.signal,
    });
    clearTimeout(timer);
    const text = await res.text();
    try { return JSON.parse(text); } catch { return text; }
  } catch (e) {
    clearTimeout(timer);
    throw e;
  }
}

// ========== Database ==========
let pool;
async function initDB() {
  pool = mysql.createPool(DB_CONFIG);
  await pool.execute(`CREATE TABLE IF NOT EXISTS opportunities (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title_en VARCHAR(255),
    title_zh VARCHAR(255),
    data JSON,
    feasibility CHAR(1) DEFAULT 'B',
    source VARCHAR(50),
    created_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_date (created_date),
    INDEX idx_feasibility (feasibility)
  )`);
  await pool.execute(`CREATE TABLE IF NOT EXISTS market_snapshots (
    id INT AUTO_INCREMENT PRIMARY KEY,
    snapshot_date DATE UNIQUE,
    data JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  )`);
  await pool.execute(`CREATE TABLE IF NOT EXISTS search_reports (
    id INT AUTO_INCREMENT PRIMARY KEY,
    keyword VARCHAR(255) NOT NULL,
    report JSON,
    raw_count INT DEFAULT 0,
    score DECIMAL(3,1),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_keyword (keyword),
    INDEX idx_created (created_at)
  )`);
  await pool.execute(`CREATE TABLE IF NOT EXISTS raw_data (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source VARCHAR(20),
    title VARCHAR(500),
    url VARCHAR(1000),
    engagement INT DEFAULT 0,
    biz_score FLOAT DEFAULT 0,
    data JSON,
    fetched_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_date (fetched_date)
  )`);
  await pool.execute(`CREATE TABLE IF NOT EXISTS analysis_tasks (
    id VARCHAR(36) PRIMARY KEY,
    type VARCHAR(30) NOT NULL,
    input JSON,
    result JSON,
    state ENUM('pending','running','done','error') DEFAULT 'pending',
    error_msg TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP NULL,
    INDEX idx_type_state (type, state),
    INDEX idx_created (created_at)
  )`);
  console.log('[DB] Tables initialized');
}

// ========== Async Analysis Task System ==========
const crypto = require('crypto');
const runningTasks = new Map(); // in-memory tracking

async function createTask(type, input) {
  const id = crypto.randomUUID();
  await pool.execute('INSERT INTO analysis_tasks (id, type, input, state) VALUES (?, ?, ?, ?)', [id, type, JSON.stringify(input), 'pending']);
  return id;
}

async function completeTask(id, result) {
  await pool.execute('UPDATE analysis_tasks SET state=?, result=?, completed_at=NOW() WHERE id=?', ['done', JSON.stringify(result), id]);
  runningTasks.delete(id);
}

async function failTask(id, errMsg) {
  await pool.execute('UPDATE analysis_tasks SET state=?, error_msg=?, completed_at=NOW() WHERE id=?', ['error', errMsg, id]);
  runningTasks.delete(id);
}

// Async market analysis
async function runMarketAnalysis(taskId) {
  try {
    await pool.execute('UPDATE analysis_tasks SET state=? WHERE id=?', ['running', taskId]);
    const [taskRows] = await pool.execute('SELECT input FROM analysis_tasks WHERE id=?', [taskId]);
    const input = typeof taskRows[0].input === 'string' ? JSON.parse(taskRows[0].input) : taskRows[0].input;
    
    const si = input.stockIndices || {};
    const crypto = input.crypto || {};
    const fg = input.fearGreed || {};
    const news = input.news || [];
    
    const stockCtx = [];
    if (si.nasdaq) stockCtx.push(`${si.nasdaq.name||'çº³æ–¯è¾¾å…‹'}: ${si.nasdaq.price} (${si.nasdaq.change>0?'+':''}${si.nasdaq.change}%)`);
    if (si.dji) stockCtx.push(`${si.dji.name||'é“ç¼æ–¯'}: ${si.dji.price} (${si.dji.change>0?'+':''}${si.dji.change}%)`);
    if (si.sse) stockCtx.push(`${si.sse.name||'ä¸Šè¯æŒ‡æ•°'}: ${si.sse.price} (${si.sse.change>0?'+':''}${si.sse.change}%)`);
    if (si.szse) stockCtx.push(`${si.szse.name||'æ·±è¯æˆæŒ‡'}: ${si.szse.price} (${si.szse.change>0?'+':''}${si.szse.change}%)`);
    if (si.hsi) stockCtx.push(`${si.hsi.name||'æ’ç”ŸæŒ‡æ•°'}: ${si.hsi.price} (${si.hsi.change>0?'+':''}${si.hsi.change}%)`);
    const cryptoCtx = crypto.btc ? `BTC:$${crypto.btc.price}(${crypto.btc.change}%) ETH:$${crypto.eth?.price}(${crypto.eth?.change}%) SOL:$${crypto.sol?.price}(${crypto.sol?.change}%)` : '';
    const fgCtx = fg.value ? `ææƒ§è´ªå©ªæŒ‡æ•°:${fg.value}(${fg.label})` : '';
    const newsCtx = news.slice(0, 8).map((n, i) => `${i+1}. ${n.title} [${n.source}]`).join('\n');
    
    const today = new Date().toISOString().split('T')[0];
    const prompt = `ä»Šå¤©${today}çš„å®žæ—¶å¸‚åœºæ•°æ®ï¼š
${stockCtx.join(' | ') || 'æ— '}
${cryptoCtx} ${fgCtx}
æ–°é—»ï¼š${newsCtx || 'æ— '}

ç”¨å¤§ç™½è¯åˆ†æžï¼Œä¸è¦é‡‘èžæœ¯è¯­ã€‚æ¯ä¸ªå¸‚åœºè¯´æ¸…æ¥šï¼šçŽ°åœ¨å•¥æƒ…å†µâ†’ä¸ºå•¥â†’æŽ¥ä¸‹æ¥ä¼šæ€Žæ ·â†’å»ºè®®ã€‚è¦æåˆ°å…·ä½“çš„å…¬å¸åå’Œäº‹ä»¶åï¼Œä¸è¦è¯´"ä¸€äº›å¤§å…¬å¸"è¿™ç§æ¨¡ç³Šçš„è¯ã€‚

è¾“å‡ºçº¯JSONï¼š
{"summary":"ä¸€å¥è¯æ€»ç»“","us_market":{"trend":"æ¶¨/è·Œ/éœ‡è¡","analysis":"3-4å¥å¤§ç™½è¯åˆ†æžï¼Œæåˆ°å…·ä½“å…¬å¸å¦‚è‹¹æžœè‹±ä¼Ÿè¾¾ç­‰","prediction":"1-2å‘¨é¢„æµ‹+åŽŸå› ","confidence":"high/medium/low"},"cn_market":{"trend":"","analysis":"æåˆ°å…·ä½“æ¿å—å¦‚æ–°èƒ½æºèŠ¯ç‰‡ç­‰","prediction":"","confidence":""},"hk_market":{"trend":"","analysis":"æåˆ°å…·ä½“å…¬å¸å¦‚è…¾è®¯é˜¿é‡Œç­‰","prediction":"","confidence":""},"crypto_market":{"trend":"","analysis":"è§£é‡Šæè´ªæŒ‡æ•°å¯¹æ™®é€šäººçš„æ„ä¹‰","prediction":"","confidence":""},"money_opportunities":"2-3æ¡èƒ½ç›´æŽ¥åšçš„èµšé’±å»ºè®®","risk_warnings":["é£Žé™©1","é£Žé™©2"]}`;

    console.log(`[task:${taskId}] Running market analysis...`);
    const result = await callLLM(prompt, 16000, 'glm-5'); // GLM-5 needs big max_tokens (thinking eats tokens)
    const parsed = tryParseJSON(result) || { summary: result.substring(0, 500) };
    parsed._analyzedAt = new Date().toISOString();
    parsed._dataSource = { stocks: 'æ–°æµªè´¢ç»', crypto: 'CoinGecko', fearGreed: 'Alternative.me', news: 'HackerNews+Reddit' };
    
    await completeTask(taskId, parsed);
    console.log(`[task:${taskId}] Market analysis done`);
  } catch (e) {
    console.error(`[task:${taskId}] Market analysis failed:`, e.message);
    await failTask(taskId, e.message);
  }
}

// Async news analysis
async function runNewsAnalysis(taskId) {
  try {
    await pool.execute('UPDATE analysis_tasks SET state=? WHERE id=?', ['running', taskId]);
    const [taskRows] = await pool.execute('SELECT input FROM analysis_tasks WHERE id=?', [taskId]);
    const input = typeof taskRows[0].input === 'string' ? JSON.parse(taskRows[0].input) : taskRows[0].input;
    const newsItems = input.news || [];
    
    const newsList = newsItems.map((n, i) => `${i+1}. [${n.source}] ${n.title}${n.url ? ' ('+n.url+')' : ''}`).join('\n');
    
    const prompt = `åˆ†æžè¿™äº›ç§‘æŠ€æ–°é—»çš„èµšé’±æœºä¼šï¼š
${newsList}

æ¯æ¡æ–°é—»ç”¨å¤§ç™½è¯è¯´ï¼šåœ¨è®²ä»€ä¹ˆâ†’ä¸ºä»€ä¹ˆè·Ÿèµšé’±æœ‰å…³â†’ç¨‹åºå‘˜èƒ½åšä»€ä¹ˆèµšé’±ï¼ˆè¦å…·ä½“å¯æ‰§è¡Œï¼‰ã€‚

è¾“å‡ºçº¯JSONæ•°ç»„ï¼š
[{"title":"æ–°é—»æ ‡é¢˜","source":"æ¥æº","relevance":"high/medium/low","analysis":"å¤§ç™½è¯è¯´æ¸…æ¥šè¿™æ¡æ–°é—»è®²ä»€ä¹ˆã€ä¸ºä»€ä¹ˆé‡è¦","money_angle":"å…·ä½“èµšé’±æ€è·¯ï¼Œèƒ½ç›´æŽ¥åŽ»åšçš„","action_items":["ç¬¬ä¸€æ­¥åšä»€ä¹ˆ","ç„¶åŽåšä»€ä¹ˆ"]}]`;
    
    console.log(`[task:${taskId}] Running news analysis (${newsItems.length} items)...`);
    const result = await callLLM(prompt, 16000, 'glm-5');
    let parsed = tryParseJSON(result);
    if (!Array.isArray(parsed)) parsed = parsed?.items || [{ analysis: result.substring(0, 500) }];
    
    const output = { analyses: parsed, _analyzedAt: new Date().toISOString(), _newsCount: newsItems.length };
    await completeTask(taskId, output);
    console.log(`[task:${taskId}] News analysis done`);
  } catch (e) {
    console.error(`[task:${taskId}] News analysis failed:`, e.message);
    await failTask(taskId, e.message);
  }
}

// ========== Data Scrapers ==========
const NEWS_JUNK = /\b(died|death|obituary|wins?\s|champion|election|president|war\s|arrest|scandal|lawsuit|court\s|judge|patent|acqui|IPO|funding|raised|nfl|nba|super bowl|oscars|grammy|holiday)\b/i;
const PAIN_SIGNALS = {
  WILLING_PAY: /\b(pay for|worth paying|shut up and take|would buy|will pay|pricing|subscription|pro plan|premium|upgrade|budget|invest in)\b/i,
  STRONG_PAIN: /\b(frustrat|hate|terrible|broken|awful|annoy|painful|suck|worst|horrible|unusable|nightmare|waste of time|give up|fed up|sick of|tired of)\b/i,
  NEED_ALT: /\b(alternative|looking for|replace|switch from|better than|instead of|need a|wish there|why isn.t there|someone should build)\b/i,
  BIZ_SIGNAL: /\b(saas|pricing|revenue|startup|monetiz|payment|subscript|customer|churn|convert|profit|market|launch|freelanc|agency|client|billing|invoice|workflow|automat)\b/i,
  SIMPLE_FIX: /\b(simple|easy|just need|basic|lightweight|minimal|tiny|small tool|quick|script|chrome extension|cli tool|bot|plugin|widget|template)\b/i,
};

function calcScore(item) {
  const text = `${item.title || ''} ${item.body || ''}`.toLowerCase();
  let base = item._source === 'hn' ? Math.min(item.points || 0, 200) + (item.num_comments || 0) * 2
    : item._source === 'google_trends' ? Math.min((item.points || 0) / 5, 300)
    : (item.reactions || 0) + (item.comments_count || 0) * 3;
  base = Math.max(base, 5);
  
  let pain = 1.0;
  const flags = [];
  if (PAIN_SIGNALS.WILLING_PAY.test(text)) { pain *= 3.0; flags.push('willing-to-pay'); }
  if (PAIN_SIGNALS.STRONG_PAIN.test(text)) { pain *= 2.5; flags.push('strong-pain'); }
  if (PAIN_SIGNALS.NEED_ALT.test(text)) { pain *= 2.0; flags.push('need-alt'); }
  if (PAIN_SIGNALS.BIZ_SIGNAL.test(text)) { pain *= 1.5; flags.push('biz-signal'); }
  if (PAIN_SIGNALS.SIMPLE_FIX.test(text)) { pain *= 1.8; flags.push('simple-fix'); }
  if (NEWS_JUNK.test(text)) { pain *= 0.05; flags.push('news-junk'); }
  
  return { score: Math.round(base * pain * 100) / 100, base, pain, flags };
}

async function fetchHN(tag, limit) {
  try {
    const data = await fetchJSON(`https://hn.algolia.com/api/v1/search?tags=${tag}&hitsPerPage=${limit}`, { timeout: 12000 });
    return (data.hits || []).map(h => ({
      id: h.objectID, title: h.title, url: h.url,
      points: h.points || 0, num_comments: h.num_comments || 0,
      created_at: h.created_at, _source: 'hn',
    }));
  } catch { return []; }
}

async function fetchHNQuery(query, limit) {
  try {
    const data = await fetchJSON(`https://hn.algolia.com/api/v1/search?query=${encodeURIComponent(query)}&tags=story&hitsPerPage=${limit}`, { timeout: 12000 });
    return (data.hits || []).map(h => ({
      id: h.objectID, title: h.title, url: h.url,
      points: h.points || 0, num_comments: h.num_comments || 0,
      created_at: h.created_at, _source: 'hn',
    }));
  } catch { return []; }
}

// Fetch HN comments for a single item using Algolia HN API
async function fetchHNComments(itemId, maxComments = 5) {
  try {
    const data = await fetchJSON(`https://hn.algolia.com/api/v1/items/${itemId}`, { timeout: 10000 });
    const allComments = data.children || [];

    // Sort by points descending, take top N
    const topComments = allComments
      .filter(c => c.text)
      .sort((a, b) => (b.points || 0) - (a.points || 0))
      .slice(0, maxComments);

    return topComments.map(c => ({
      text: (c.text || '').replace(/<[^>]*>/g, ' ').replace(/\s+/g, ' ').trim().substring(0, 200),
      author: c.author || 'unknown',
      points: c.points || 0,
    }));
  } catch (e) {
    console.error(`[fetchHNComments] Error fetching comments for item ${itemId}:`, e.message);
    return [];
  }
}

// Fetch comments for multiple HN items with rate limiting (serial + 200ms delay)
async function fetchHNCommentsBatch(items, maxPerItem = 5) {
  const comments = {};
  for (const item of items) {
    if (!item.id) continue;
    try {
      const itemComments = await fetchHNComments(item.id, maxPerItem);
      comments[item.id] = itemComments;
      console.log(`[HN Comments] Fetched ${itemComments.length} comments for item ${item.id}`);
      // Rate limiting: 200ms delay between requests
      await new Promise(r => setTimeout(r, 200));
    } catch (e) {
      console.error(`[HN Comments] Failed for ${item.id}:`, e.message);
    }
  }
  return comments;
}

async function fetchGH(query, limit) {
  try {
    const data = await fetchJSON(
      `https://api.github.com/search/issues?q=${encodeURIComponent(query)}&sort=reactions&per_page=${limit}`,
      { timeout: 12000, headers: { 'User-Agent': 'PainRadar', 'Accept': 'application/vnd.github.v3+json' } }
    );
    return (data.items || []).map(i => ({
      id: i.id, title: i.title, url: i.html_url,
      body: (i.body || '').substring(0, 500),
      reactions: i.reactions?.total_count || 0,
      comments_count: i.comments || 0,
      created_at: i.created_at, _source: 'github',
    }));
  } catch { return []; }
}

// ========== New Data Source Fetchers ==========

// Fetch Ask HN posts - strong pain signal source
async function fetchAskHN(limit = 30) {
  try {
    const data = await fetchJSON(
      `https://hn.algolia.com/api/v1/search?query=Ask%20HN&tags=ask_hn&hitsPerPage=${limit}`,
      { timeout: 12000 }
    );
    return (data.hits || []).map(h => ({
      id: h.objectID,
      title: h.title,
      url: h.url || `https://news.ycombinator.com/item?id=${h.objectID}`,
      points: h.points || 0,
      num_comments: h.num_comments || 0,
      created_at: h.created_at,
      _source: 'ask_hn',
    }));
  } catch (e) {
    console.error('[fetchAskHN] Error:', e.message);
    return [];
  }
}

// Fetch Stack Overflow high-vote questions
async function fetchStackOverflow(pagesize = 30) {
  try {
    // Fetch recent hot questions across popular dev tags
    const tags = ['python', 'javascript', 'api', 'automation', 'web-scraping', 'docker', 'aws', 'stripe'];
    const allItems = [];
    for (const tag of tags.slice(0, 3)) { // limit to 3 calls to avoid rate limit
      try {
        const data = await fetchJSON(
          `https://api.stackexchange.com/2.3/questions?order=desc&sort=activity&site=stackoverflow&tagged=${tag}&pagesize=10&filter=!nNPvSNP4(R`,
          { timeout: 10000 }
        );
        for (const i of (data.items || [])) {
          allItems.push({
            id: i.question_id,
            title: i.title,
            url: i.link,
            score: i.score || 0,
            view_count: i.view_count || 0,
            tags: i.tags || [],
            answer_count: i.answer_count || 0,
            creation_date: i.creation_date ? new Date(i.creation_date * 1000).toISOString() : null,
            _source: 'stackoverflow',
          });
        }
      } catch {}
    }
    console.log(`[fetchStackOverflow] ${allItems.length} questions`);
    return allItems;
  } catch (e) {
    console.error('[fetchStackOverflow] Error:', e.message);
    return [];
  }
}

// Fetch GitHub issues - feature requests with reactions
async function fetchGitHubIssues(limit = 30) {
  try {
    const results = [];

    // Query 1: enhancement label with reactions > 5
    try {
      const data1 = await fetchJSON(
        `https://api.github.com/search/issues?q=label:enhancement+state:open+reactions:>5&sort=reactions&per_page=${limit}`,
        { timeout: 12000, headers: { 'User-Agent': 'PainRadar', 'Accept': 'application/vnd.github.v3+json' } }
      );
      (data1.items || []).forEach(i => {
        results.push({
          id: i.id,
          title: i.title,
          url: i.html_url,
          body: (i.body || '').substring(0, 500),
          reactions: i.reactions?.total_count || 0,
          comments_count: i.comments || 0,
          repository_url: i.repository_url,
          created_at: i.created_at,
          _source: 'github_issues',
        });
      });
    } catch (e) {
      console.error('[fetchGitHubIssues] Query 1 error:', e.message);
    }

    // Query 2: feature-request label with reactions > 3
    try {
      const data2 = await fetchJSON(
        `https://api.github.com/search/issues?q=label:feature-request+state:open+reactions:>3&sort=reactions&per_page=${limit}`,
        { timeout: 12000, headers: { 'User-Agent': 'PainRadar', 'Accept': 'application/vnd.github.v3+json' } }
      );
      (data2.items || []).forEach(i => {
        // Avoid duplicates
        if (!results.find(r => r.id === i.id)) {
          results.push({
            id: i.id,
            title: i.title,
            url: i.html_url,
            body: (i.body || '').substring(0, 500),
            reactions: i.reactions?.total_count || 0,
            comments_count: i.comments || 0,
            repository_url: i.repository_url,
            created_at: i.created_at,
            _source: 'github_issues',
          });
        }
      });
    } catch (e) {
      console.error('[fetchGitHubIssues] Query 2 error:', e.message);
    }

    // Sort by reactions
    results.sort((a, b) => b.reactions - a.reactions);
    return results.slice(0, limit * 2);
  } catch (e) {
    console.error('[fetchGitHubIssues] Error:', e.message);
    return [];
  }
}

// Fetch GitHub issue comments for a single issue
// issueUrl format: https://api.github.com/repos/{owner}/{repo}/issues/{number}
async function fetchGitHubIssueComments(issueUrl, maxComments = 5) {
  try {
    // Convert HTML URL to API URL if needed
    // e.g., https://github.com/owner/repo/issues/123 -> https://api.github.com/repos/owner/repo/issues/123/comments
    let commentsUrl;
    if (issueUrl.includes('api.github.com')) {
      commentsUrl = issueUrl.replace('/issues/', '/issues/').replace(/\/\d+$/, '') + '/comments';
    } else {
      // Parse HTML URL: https://github.com/owner/repo/issues/123
      const match = issueUrl.match(/github\.com\/([^/]+)\/([^/]+)\/issues\/(\d+)/);
      if (!match) return [];
      const [, owner, repo, issueNum] = match;
      commentsUrl = `https://api.github.com/repos/${owner}/${repo}/issues/${issueNum}/comments?per_page=${maxComments}`;
    }

    const data = await fetchJSON(commentsUrl, {
      timeout: 10000,
      headers: { 'User-Agent': 'PainRadar', 'Accept': 'application/vnd.github.v3+json' }
    });

    if (!Array.isArray(data)) return [];

    return data.slice(0, maxComments).map(c => ({
      text: (c.body || '').replace(/\r?\n/g, ' ').trim().substring(0, 200),
      author: c.user?.login || 'unknown',
      created_at: c.created_at,
    }));
  } catch (e) {
    console.error(`[fetchGitHubIssueComments] Error for ${issueUrl}:`, e.message);
    return [];
  }
}

// Fetch comments for top GitHub issues (by biz_score)
async function fetchGitHubCommentsBatch(items, maxItems = 10, maxPerItem = 5) {
  // Only fetch comments for top items by biz_score
  const topItems = items
    .filter(i => i._source === 'github_issues' && i.url)
    .slice(0, maxItems);

  const comments = {};
  for (const item of topItems) {
    try {
      const itemComments = await fetchGitHubIssueComments(item.url, maxPerItem);
      comments[item.id] = itemComments;
      console.log(`[GH Comments] Fetched ${itemComments.length} comments for issue ${item.id}`);
      // Small delay to avoid rate limit
      await new Promise(r => setTimeout(r, 100));
    } catch (e) {
      console.error(`[GH Comments] Failed for ${item.id}:`, e.message);
    }
  }
  return comments;
}

// Fetch Reddit pain points via RSS (JSON API blocked by Cloudflare 403)
function stripHtmlRss(html) {
  if (!html) return '';
  return html.replace(/<[^>]*>/g, ' ').replace(/&amp;/g, '&').replace(/&lt;/g, '<').replace(/&gt;/g, '>').replace(/&quot;/g, '"').replace(/&#39;/g, "'").replace(/&nbsp;/g, ' ').replace(/\s+/g, ' ').trim();
}

function decodeXmlEnt(str) {
  if (!str) return '';
  return str.replace(/&amp;/g, '&').replace(/&lt;/g, '<').replace(/&gt;/g, '>').replace(/&quot;/g, '"').replace(/&apos;/g, "'").replace(/&#(\d+);/g, (m, c) => String.fromCharCode(parseInt(c))).replace(/&#x([0-9a-fA-F]+);/g, (m, c) => String.fromCharCode(parseInt(c, 16)));
}

function parseRssEntries(xml, subreddit) {
  const items = [];
  const entryRegex = /<entry[\s\S]*?<\/entry>/gi;
  let match;
  while ((match = entryRegex.exec(xml)) !== null) {
    const entry = match[0];
    const titleM = entry.match(/<title[^>]*>([^<]*)<\/title>/i);
    const title = titleM ? decodeXmlEnt(titleM[1]) : '';
    const linkM = entry.match(/<link[^>]*href="([^"]*)"[^>]*>/i);
    const url = linkM ? linkM[1] : '';
    const authorM = entry.match(/<author[\s\S]*?<name>([^<]*)<\/name>/i);
    const author = authorM ? decodeXmlEnt(authorM[1]) : 'unknown';
    const contentM = entry.match(/<content[^>]*>([\s\S]*?)<\/content>/i);
    const body = stripHtmlRss(contentM ? contentM[1] : '').substring(0, 500);
    const idM = entry.match(/<id>([^<]*)<\/id>/i);
    const id = idM ? idM[1].replace('t3_', '') : `rss-${Date.now()}`;
    const pubM = entry.match(/<published>([^<]*)<\/published>/i) || entry.match(/<updated>([^<]*)<\/updated>/i);
    const created_at = pubM ? pubM[1] : new Date().toISOString();
    if (title && url) {
      items.push({ id, title, url, body, score: 0, num_comments: 0, subreddit, created_at, _source: 'reddit', _rss_mode: true });
    }
  }
  return items;
}

async function fetchRedditPainPoints(limit = 50) {
  const subs = ['SaaS', 'startups', 'Entrepreneur', 'smallbusiness', 'sideproject'];
  const allItems = [];
  for (const sub of subs) {
    try {
      const url = `https://www.reddit.com/r/${sub}/.rss?limit=25`;
      const cmd = `curl -sL --max-time 15 -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:128.0) Gecko/20100101 Firefox/128.0' '${url}'`;
      const xml = execSync(cmd, { timeout: 20000, encoding: 'utf-8' });
      const items = parseRssEntries(xml, sub);
      allItems.push(...items);
      console.log(`[Reddit RSS] r/${sub}: ${items.length} posts`);
    } catch (e) {
      console.log(`[Reddit RSS] r/${sub} failed: ${e.message}`);
    }
  }
  console.log(`[Reddit RSS] Total: ${allItems.length} posts from ${subs.length} subs`);
  return allItems;
}

// New pain signal keywords for pre-filtering
const PAIN_SIGNAL_KEYWORDS = [
  /i'd pay|shut up and take my money|willing to pay|take my money/i,
  /frustrated with|hate using|wish there was|tired of/i,
  /switching from|alternative to|better than|looking for/i,
  /how do you handle|what do you use for|anyone built|is there a/i,
  /pain point|struggle with|annoying|waste of time/i,
];

// Match pain signals and tag items
function matchPainSignals(item) {
  const text = `${item.title || ''} ${item.body || ''}`;
  const matchedKeywords = [];

  for (const pattern of PAIN_SIGNAL_KEYWORDS) {
    if (pattern.test(text)) {
      const match = text.match(pattern);
      if (match) {
        matchedKeywords.push(match[0]);
      }
    }
  }

  item._painSignals = matchedKeywords;
  return matchedKeywords.length > 0;
}

async function fetchAllData() {
  const results = await Promise.allSettled([
    // Original sources
    fetchHN('ask_hn', 30),
    fetchHN('show_hn', 30),
    fetchHNQuery('frustrated OR "looking for" OR alternative OR "need a"', 25),
    fetchHNQuery('pricing OR "pay for" OR subscription OR "worth paying"', 20),
    fetchHNQuery('simple tool OR chrome extension OR cli OR "side project"', 20),
    fetchGH('frustrated OR broken OR unusable type:issue sort:reactions', 20),
    fetchGH('feature request OR enhancement type:issue sort:reactions', 20),
    fetchGH('"looking for alternative" OR "switch from" type:issue sort:reactions', 15),
    // New data sources
    fetchAskHN(30),
    fetchStackOverflow(30),
    fetchGitHubIssues(30),
    fetchRedditPainPoints(50),
  ]);

  const items = [];
  const seen = new Set();
  results.forEach(r => {
    if (r.status !== 'fulfilled') return;
    r.value.forEach(item => {
      const key = item.id || item.title;
      if (seen.has(key)) return;
      seen.add(key);
      // Apply pain signal matching
      matchPainSignals(item);
      items.push(item);
    });
  });

  items.forEach(i => { i._score = calcScore(i); });
  // Sort: items with pain signals first, then by score
  items.sort((a, b) => {
    const aPain = a._painSignals?.length || 0;
    const bPain = b._painSignals?.length || 0;
    if (aPain !== bPain) return bPain - aPain;
    return b._score.score - a._score.score;
  });

  // ========== Fetch comments for top items ==========
  console.log('[fetchAllData] Fetching comments for top items...');

  // Get top HN items for comment fetching
  const hnItems = items.filter(i => (i._source === 'hn' || i._source === 'ask_hn')).slice(0, 15);
  if (hnItems.length > 0) {
    try {
      const hnComments = await fetchHNCommentsBatch(hnItems, 5);
      // Attach comments to items
      for (const item of hnItems) {
        if (hnComments[item.id]) {
          item.comments = hnComments[item.id];
        }
      }
    } catch (e) {
      console.error('[fetchAllData] HN comment fetch failed:', e.message);
    }
  }

  // Get top GitHub Issues for comment fetching
  const ghItems = items.filter(i => i._source === 'github_issues').slice(0, 10);
  if (ghItems.length > 0) {
    try {
      const ghComments = await fetchGitHubCommentsBatch(ghItems, 10, 5);
      // Attach comments to items
      for (const item of ghItems) {
        if (ghComments[item.id]) {
          item.comments = ghComments[item.id];
        }
      }
    } catch (e) {
      console.error('[fetchAllData] GH comment fetch failed:', e.message);
    }
  }

  const totalComments = items.reduce((sum, i) => sum + (i.comments?.length || 0), 0);
  console.log(`[fetchAllData] Total comments fetched: ${totalComments}`);

  return items;
}

// ========== Market Data (Real Sources) ==========

// Yahoo Finance v8 - ç¾Žè‚¡/æ¸¯è‚¡æŒ‡æ•° (with User-Agent to avoid 429)
async function fetchYahooQuote(symbol) {
  try {
    const url = `https://query1.finance.yahoo.com/v8/finance/chart/${encodeURIComponent(symbol)}?interval=1d&range=2d`;
    const res = await fetch(url, { 
      timeout: 10000,
      headers: { 'User-Agent': 'Mozilla/5.0 (compatible; PainRadar/1.0)' }
    });
    if (!res.ok) return null;
    const data = await res.json();
    const result = data?.chart?.result?.[0];
    if (!result) return null;
    const meta = result.meta;
    const prev = meta.chartPreviousClose || meta.previousClose;
    const cur = meta.regularMarketPrice;
    if (!cur) return null;
    const change = prev ? Math.round((cur - prev) / prev * 10000) / 100 : 0;
    return { price: cur, change, currency: meta.currency, source: 'Yahoo Finance', sourceType: 'real' };
  } catch { return null; }
}

// æ–°æµªè´¢ç» - Aè‚¡/æ¸¯è‚¡/ç¾Žè‚¡æŒ‡æ•° (GBK encoded)
async function fetchSinaStock(symbol) {
  try {
    const res = await fetch(`https://hq.sinajs.cn/list=${symbol}`, {
      headers: { 'Referer': 'https://finance.sina.com.cn' },
      signal: AbortSignal.timeout(8000),
    });
    // Handle GBK encoding
    let text;
    try {
      const buf = Buffer.from(await res.arrayBuffer());
      text = new TextDecoder('gbk').decode(buf);
    } catch {
      text = await res.text(); // fallback to UTF-8
    }
    const match = text.match(/"(.+)"/);
    if (!match) return null;
    const parts = match[1].split(',');
    // s_sh000001/int_* ç®€ç‰ˆæ ¼å¼: åç§°,æœ€æ–°,æ¶¨è·Œé¢,æ¶¨è·Œå¹…,...
    const name = parts[0], cur = parseFloat(parts[1]), changePct = parseFloat(parts[3]);
    if (!cur || isNaN(cur)) return null;
    return { price: cur, change: changePct, name, source: 'æ–°æµªè´¢ç»', sourceType: 'real' };
  } catch (e) { console.error(`[sina] ${symbol} error:`, e.message); return null; }
}

// HackerNews top stories for tech news
async function fetchHNTopNews(limit = 5) {
  try {
    const data = await fetchJSON('https://hn.algolia.com/api/v1/search?tags=front_page&hitsPerPage=' + limit, { timeout: 10000 });
    return (data?.hits || []).map(h => ({
      title: h.title,
      url: h.url || `https://news.ycombinator.com/item?id=${h.objectID}`,
      points: h.points,
      source: 'HackerNews',
      sourceType: 'real'
    }));
  } catch { return []; }
}

// Reddit trending in tech/startup subs (via RSS)
async function fetchRedditTrending(sub = 'technology', limit = 5) {
  try {
    const url = `https://www.reddit.com/r/${sub}/.rss?limit=${limit}`;
    const cmd = `curl -sL --max-time 15 -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:128.0) Gecko/20100101 Firefox/128.0' '${url}'`;
    const xml = execSync(cmd, { timeout: 20000, encoding: 'utf-8' });
    return parseRssEntries(xml, sub).map(item => ({
      title: item.title,
      url: item.url,
      score: 0,
      source: `Reddit r/${sub}`,
      sourceType: 'real'
    }));
  } catch { return []; }
}

async function fetchMarketData() {
  const [crypto, fg, ndx, dji, sse, szse, hsi, hnNews, reddit, redditStartup] = await Promise.allSettled([
    fetchJSON('https://api.coingecko.com/api/v3/simple/price?ids=bitcoin,ethereum,solana&vs_currencies=usd&include_24hr_change=true', { timeout: 10000 }),
    fetchJSON('https://api.alternative.me/fng/?limit=1', { timeout: 8000 }),
    fetchSinaStock('int_nasdaq'),   // çº³æ–¯è¾¾å…‹ (æ–°æµªå›½é™…æŒ‡æ•°)
    fetchSinaStock('int_dji'),      // é“ç¼æ–¯
    fetchSinaStock('s_sh000001'),   // ä¸Šè¯æŒ‡æ•°
    fetchSinaStock('s_sz399001'),   // æ·±è¯æˆæŒ‡
    fetchSinaStock('int_hangseng'), // æ’ç”ŸæŒ‡æ•°
    fetchHNTopNews(5),
    fetchRedditTrending('technology', 3),
    fetchRedditTrending('SaaS', 3),
  ]);
  
  // Crypto
  let cryptoData = null;
  if (crypto.status === 'fulfilled' && typeof crypto.value === 'object') {
    const d = crypto.value;
    const fmt = (id) => { const c = d[id]; return c ? { price: c.usd, change: Math.round((c.usd_24h_change || 0) * 100) / 100, source: 'CoinGecko', sourceType: 'real' } : null; };
    cryptoData = { btc: fmt('bitcoin'), eth: fmt('ethereum'), sol: fmt('solana') };
  }
  
  // Fear & Greed
  let fearGreed = null;
  if (fg.status === 'fulfilled' && fg.value?.data?.[0]) {
    const item = fg.value.data[0];
    fearGreed = { value: parseInt(item.value), label: item.value_classification, source: 'Alternative.me', sourceType: 'real' };
  }
  
  // Stock indices (from Sina)
  const stocks = {};
  if (ndx.status === 'fulfilled' && ndx.value) stocks.nasdaq = ndx.value;
  if (dji.status === 'fulfilled' && dji.value) stocks.dji = dji.value;
  if (sse.status === 'fulfilled' && sse.value) stocks.sse = sse.value;
  if (szse.status === 'fulfilled' && szse.value) stocks.szse = szse.value;
  if (hsi.status === 'fulfilled' && hsi.value) stocks.hsi = hsi.value;
  
  // News
  const news = [
    ...(hnNews.status === 'fulfilled' ? hnNews.value : []),
    ...(reddit.status === 'fulfilled' ? reddit.value : []),
    ...(redditStartup.status === 'fulfilled' ? redditStartup.value : []),
  ];
  
  return { crypto: cryptoData, fearGreed, stockIndices: stocks, news };
}

// ========== LLM Analysis (Streaming, Event-Driven) ==========
async function callLLM(prompt, maxTokens = 4000, model = 'glm-5') {
  if (!ZHIPU_KEY) throw new Error('No ZHIPU_API_KEY');
  
  // Use streaming to avoid timeout issues with long generations
  const res = await fetch('https://open.bigmodel.cn/api/coding/paas/v4/chat/completions', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${ZHIPU_KEY}` },
    body: JSON.stringify({
      model, messages: [{ role: 'user', content: prompt }],
      max_tokens: maxTokens, temperature: 0.4,
      stream: true,
    }),
  });
  
  if (!res.ok) {
    const errText = await res.text();
    throw new Error(`LLM API ${res.status}: ${errText.substring(0, 200)}`);
  }
  
  // Read SSE stream event by event
  let content = '';
  let reasoning = '';
  const reader = res.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    buffer += decoder.decode(value, { stream: true });
    
    // Process complete SSE lines
    const lines = buffer.split('\n');
    buffer = lines.pop() || ''; // Keep incomplete line in buffer
    
    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const data = line.substring(6).trim();
      if (data === '[DONE]') continue;
      
      try {
        const chunk = JSON.parse(data);
        const delta = chunk.choices?.[0]?.delta;
        if (delta?.content) content += delta.content;
        if (delta?.reasoning_content) reasoning += delta.reasoning_content;
      } catch {}
    }
  }
  
  console.log(`[LLM] ${model}: content=${content.length}c, reasoning=${reasoning.length}c`);
  
  // GLM-5 thinking model: content has the final answer, reasoning has the thought process
  // If content is empty, try to extract JSON from reasoning
  if (content.trim()) return content;
  
  // Fallback: extract JSON from reasoning
  if (reasoning) {
    // Try to find JSON object or array in reasoning
    const jsonMatch = reasoning.match(/(\{[\s\S]*\}|\[[\s\S]*\])/);
    if (jsonMatch) {
      console.log(`[LLM] Extracted JSON from reasoning (${jsonMatch[0].length}c)`);
      return jsonMatch[0];
    }
  }
  return reasoning;
}

function tryParseJSON(text) {
  if (!text) return null;
  
  // Helper: fix common JSON issues from LLMs
  function fixJSON(s) {
    // Fix single quotes used as string delimiters: "key": 'value' â†’ "key": "value"
    // Match pattern: ": '" at field value position, replace with ": "
    s = s.replace(/:\s*'([^']*?)'/g, (m, val) => ': "' + val.replace(/"/g, '\\"') + '"');
    return s;
  }
  
  try { return JSON.parse(text); } catch {}
  try { return JSON.parse(fixJSON(text)); } catch {}
  
  const m1 = text.match(/```(?:json)?\s*\n?([\s\S]*?)\n?\s*```/);
  if (m1) {
    try { return JSON.parse(m1[1]); } catch {}
    try { return JSON.parse(fixJSON(m1[1])); } catch {}
  }
  
  const m2 = text.match(/\[[\s\S]*\]/);
  if (m2) {
    try { return JSON.parse(m2[0]); } catch {}
    try { return JSON.parse(fixJSON(m2[0])); } catch {}
  }
  
  // æˆªæ–­ä¿®å¤ (with quote fix)
  if (m2) {
    const fixed = fixJSON(m2[0]);
    const boundaries = [];
    const re = /\}\s*,\s*\{/g;
    let bm;
    while ((bm = re.exec(fixed)) !== null) boundaries.push(bm.index);
    for (let i = boundaries.length - 1; i >= 0; i--) {
      try { return JSON.parse(fixed.substring(0, boundaries[i] + 1) + ']'); } catch {}
    }
  }
  return null;
}

// ========== Status & Analysis ==========
let status = { state: 'idle', progress: 0, message: '' };

async function runFullAnalysis() {
  if (status.state === 'running') return;
  status = { state: 'running', progress: 5, message: 'ðŸ“¡ æŠ“å–ç¤¾åŒºæ•°æ®...' };
  const today = new Date().toISOString().split('T')[0];
  
  try {
    // 1. Fetch raw data
    const items = await fetchAllData();
    console.log(`[fetch] ${items.length} items`);
    status.progress = 25;
    status.message = `ðŸ§  AIåˆ†æž ${items.length} æ¡æ•°æ®...`;
    
    // 2. Save raw data to DB (with full content and pain signals)
    const conn = await pool.getConnection();
    try {
      for (const item of items.filter(i => !NEWS_JUNK.test(i.title)).slice(0, 100)) {
        // Build comprehensive data object
        const fullData = {
          // Original content
          original: {
            title: item.title,
            url: item.url,
            body: item.body || null,
            points: item.points || null,
            num_comments: item.num_comments || null,
            reactions: item.reactions || null,
            score: item.score || null,
            view_count: item.view_count || null,
            tags: item.tags || null,
            subreddit: item.subreddit || null,
            repository_url: item.repository_url || null,
            created_at: item.created_at || null,
          },
          // Comments (fetched from HN/GitHub)
          comments: item.comments || [],
          // Pain signal analysis results
          painAnalysis: {
            matchedKeywords: item._painSignals || [],
            hasPainSignals: (item._painSignals || []).length > 0,
            score: item._score?.score || 0,
            baseScore: item._score?.base || 0,
            painMultiplier: item._score?.pain || 1,
            flags: item._score?.flags || [],
          },
          // Source metadata
          source: item._source,
          fetchedAt: new Date().toISOString(),
        };

        await conn.execute(
          'INSERT IGNORE INTO raw_data (source, title, url, engagement, biz_score, data, fetched_date) VALUES (?, ?, ?, ?, ?, ?, ?)',
          [
            item._source || 'unknown',
            item.title || '',
            item.url || '',
            item.points || item.reactions || item.score || 0,
            item._score?.score || 0,
            JSON.stringify(fullData),
            today
          ]
        );
      }
    } finally { conn.release(); }
    
    // 3. LLM Analysis - prioritize items with pain signals
    const top = items.filter(i => !NEWS_JUNK.test(i.title)).slice(0, 25);
    const itemList = top.map((item, i) => {
      const srcMap = {
        'hn': 'HN', 'github': 'GH', 'ask_hn': 'AskHN',
        'stackoverflow': 'SO', 'github_issues': 'GHIssues', 'reddit': 'Reddit'
      };
      const src = srcMap[item._source] || item._source;
      let eng = '';
      if (item._source === 'hn' || item._source === 'ask_hn') {
        eng = `${item.points || 0}èµž/${item.num_comments || 0}è¯„`;
      } else if (item._source === 'stackoverflow') {
        eng = `${item.score || 0}ç¥¨/${item.view_count || 0}æµè§ˆ`;
      } else if (item._source === 'reddit') {
        eng = `${item.score || 0}èµž/${item.num_comments || 0}è¯„`;
      } else {
        eng = `${item.reactions || 0}ååº”/${item.comments_count || 0}è¯„`;
      }
      const flags = (item._score?.flags || []).join(',');
      const painSignals = (item._painSignals || []).slice(0, 2).join('; ');

      // Build comment summary (up to 3 most valuable comments)
      let commentSummary = '';
      if (item.comments && item.comments.length > 0) {
        // Select comments containing pain signal keywords
        const painKeywords = ['pay', 'frustrated', 'hate', 'alternative', 'looking for', 'need', 'wish', 'expensive', 'suck', 'broken', 'annoying'];
        const scoredComments = item.comments.map(c => {
          const text = (c.text || '').toLowerCase();
          let score = c.points || 1;
          for (const kw of painKeywords) {
            if (text.includes(kw)) score += 10;
          }
          return { ...c, _score: score };
        }).sort((a, b) => b._score - a._score);

        const topComments = scoredComments.slice(0, 3);
        if (topComments.length > 0) {
          const quotes = topComments.map(c => `"${c.text.substring(0, 80)}${c.text.length > 80 ? '...' : ''}"`);
          commentSummary = `\n   ðŸ’¬ è¯„è®ºæ‘˜è¦: ${quotes.join(' | ')}`;
        }
      }

      return `${i+1}. [${src}] ${item.title} | ${eng} | ${flags}${painSignals ? ' | ðŸ’¢' + painSignals : ''}${commentSummary}`;
    }).join('\n');

    const prompt = `ä½ æ˜¯å¸®ç¨‹åºå‘˜æ‰¾å‰¯ä¸šé¡¹ç›®çš„å•†æœºåˆ†æžå¸ˆã€‚ä»Žä»¥ä¸‹ç¤¾åŒºè®¨è®ºä¸­æ‰¾å‡º10ä¸ª"ä¸€ä¸ªäººå°±èƒ½åšã€èƒ½æ”¶è´¹ã€ç”¨æˆ·çœŸçš„ä¼šä»˜é’±"çš„äº§å“æœºä¼šã€‚

å…³é”®åŽŸåˆ™ï¼š
- åªæŽ¨èä¸€ä¸ªç¨‹åºå‘˜1-4å‘¨èƒ½åšå‡ºMVPçš„é¡¹ç›®
- å¿…é¡»æœ‰æ˜Žç¡®çš„ä»˜è´¹ç”¨æˆ·ç¾¤ï¼ˆè°ä¼šä»˜é’±ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿï¼‰
- è¦è¯´æ¸…æ¥š"çŽ°åœ¨ç”¨çš„æ–¹æ¡ˆæœ‰ä»€ä¹ˆé—®é¢˜"â†’"æˆ‘ä»¬åšä»€ä¹ˆ"â†’"æ€Žä¹ˆæ”¶é’±"
- ä¸è¦æŽ¨èéœ€è¦æ‰“è´¥å¤§å…¬å¸çš„é¡¹ç›®ï¼ˆæ¯”å¦‚åšæœç´¢å¼•æ“Žã€åšæµè§ˆå™¨ï¼‰
- Chromeæ’ä»¶ã€Telegram/Discord Botã€APIæœåŠ¡ã€å°å·¥å…·ç½‘ç«™ã€CLIå·¥å…·è¿™äº›éƒ½æ˜¯å¥½æ–¹å‘

**é‡è¦ï¼šåŒºåˆ†éœ€æ±‚ç±»åž‹**
- ä»”ç»†åˆ†æžæ¯æ¡è®¨è®ºï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯çœŸçš„åœ¨æ‰¾è§£å†³æ–¹æ¡ˆï¼ˆdirect_demandï¼‰ï¼Œè¿˜æ˜¯åªæ˜¯åœ¨è®¨è®ºæŠ€æœ¯é—®é¢˜ï¼ˆinferredï¼‰
- ä¼˜å…ˆé€‰æ‹©é‚£äº›æ˜Žç¡®è¡¨è¾¾"æˆ‘åœ¨æ‰¾X"ã€"æœ‰æ²¡æœ‰æ›¿ä»£å“"ã€"æ„¿æ„ä»˜è´¹"çš„å¸–å­
- å¦‚æžœåªæ˜¯æŠ€æœ¯è®¨è®ºæˆ–åˆ†äº«ç»éªŒï¼Œæ ‡æ³¨ä¸º inferredï¼Œè¿™ç±»å•†æœºæŽ’åœ¨åŽé¢

ç¤¾åŒºæ•°æ®ï¼š
${itemList}

è¾“å‡ºJSONæ•°ç»„ï¼Œæ¯ä¸ªå•†æœºç”¨å¤§ç™½è¯è¯´æ¸…æ¥šï¼š
[{
  "en": {"title":"äº§å“åï¼ˆè‹±æ–‡ï¼Œç®€çŸ­ï¼‰","description":"ä¸€å¥è¯è¯´æ¸…æ¥šåšä»€ä¹ˆ","originalProblem":"ç”¨æˆ·çŽ°åœ¨é‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼ˆå…·ä½“ï¼Œå¼•ç”¨ç¤¾åŒºè®¨è®ºï¼‰","whyNow":"ä¸ºä»€ä¹ˆçŽ°åœ¨åšè¿™ä¸ªæ—¶æœºå¥½","monetization":"æ€Žä¹ˆæ”¶é’±ï¼ˆå…·ä½“å®šä»·ï¼Œå¦‚æœˆè´¹$9/å¹´è´¹$49ï¼‰","targetUser":"è°ä¼šä¹°å•ï¼ˆè¶Šå…·ä½“è¶Šå¥½ï¼‰","devCost":"ä¸€ä¸ªäººå¤šä¹…èƒ½åšå‡ºæ¥","competition":"ä¸»è¦ç«žå“æ˜¯è°ï¼Œæˆ‘ä»¬å‡­ä»€ä¹ˆèƒ½èµ¢","evidence":"ç¤¾åŒºé‡Œçš„çœŸå®žè¯æ®"},
  "zh": {"title":"ä¸­æ–‡å","description":"","originalProblem":"","whyNow":"","monetization":"","targetUser":"","devCost":"","competition":"","evidence":""},
  "tags":{"platform":["Web"],"audience":["Developers"],"payWillingness":"High","category":"SaaS Tool"},
  "feasibility":"A/B/C",
  "heatLevel":"ðŸ”¥ðŸ”¥ðŸ”¥",
  "sources":["HackerNews"],
  "attention":"High/Medium/Low",
  "evidenceStrength":"Strong/Medium/Weak",
  "evidence_type":"direct_demand",
  "suggestedKeyword":"æœç´¢å…³é”®è¯"
}]

**evidence_type è¯´æ˜Žï¼ˆå¿…é¡»å¡«å†™ï¼‰ï¼š**
- direct_demandï¼šç”¨æˆ·ç›´æŽ¥è¯´"æˆ‘åœ¨æ‰¾X"ã€"æœ‰æ²¡æœ‰æ›¿ä»£"ã€"æ„¿æ„ä»˜è´¹"ç­‰æ˜Žç¡®éœ€æ±‚ä¿¡å·
- inferredï¼šä»Žè®¨è®ºä¸­æŽ¨æµ‹å‡ºæ¥çš„éœ€æ±‚ï¼Œç”¨æˆ·æ²¡æœ‰ç›´æŽ¥è¡¨è¾¾

**æŽ’åºè§„åˆ™ï¼š** direct_demand çš„å•†æœºå¿…é¡»æŽ’åœ¨æ•°ç»„å‰é¢ï¼Œinferred çš„æŽ’åœ¨åŽé¢ã€‚

A=ä¸€ä¸ªäºº1-4å‘¨èƒ½åšå‡ºæ”¶è´¹ç‰ˆæœ¬
B=éœ€è¦1-3ä¸ªæœˆæˆ–éœ€è¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†
C=ä¸åˆ‡å®žé™…ï¼ˆç›´æŽ¥æŽ’é™¤ï¼Œä¸è¦è¾“å‡ºCçº§çš„ï¼‰

æ³¨æ„ï¼šä¸è¦è¾“å‡ºCçº§é¡¹ç›®ã€‚åªç»™çœŸæ­£èƒ½ä¸‹æ‰‹çš„Aå’ŒBã€‚evidenceç”¨çº¯æ–‡æœ¬ä¸è¦å¼•å·ã€‚åªè¾“å‡ºJSONã€‚`;

    console.log(`[analyze] Calling LLM...`);
    const llmResult = await callLLM(prompt, 16000);
    console.log(`[analyze] Response: ${llmResult.length} chars`);
    // Debug: save raw response
    try { require('fs').writeFileSync('/tmp/painradar-debug-llm.txt', llmResult); } catch {}
    
    let opportunities = tryParseJSON(llmResult);
    if (!opportunities) { 
      console.error('[analyze] JSON parse failed, first 300:', llmResult.substring(0, 300));
      console.error('[analyze] JSON parse failed, last 200:', llmResult.substring(llmResult.length - 200));
      opportunities = []; 
    }
    if (!Array.isArray(opportunities)) opportunities = opportunities.items || [];
    console.log(`[analyze] Parsed ${opportunities.length} opportunities`);
    
    status.progress = 60;
    status.message = 'ðŸ“Š èŽ·å–å¸‚åœºæ•°æ®...';
    
    // 4. Save opportunities to DB
    const conn2 = await pool.getConnection();
    try {
      for (const opp of opportunities) {
        await conn2.execute(
          'INSERT INTO opportunities (title_en, title_zh, data, feasibility, source, created_date) VALUES (?, ?, ?, ?, ?, ?)',
          [opp.en?.title || null, opp.zh?.title || null, JSON.stringify(opp), opp.feasibility || 'B', (opp.sources || [])[0] || 'HN', today]
        );
      }
    } finally { conn2.release(); }
    
    // 5. Market data - FETCH FIRST, NO LLM (prevent OOM on shared hosting)
    let market = { crypto: null, fearGreed: null, stockIndices: {}, news: [] };
    try {
      market = await fetchMarketData();
      console.log(`[market] Fetched: ${Object.keys(market.stockIndices || {}).length} indices, ${(market.news || []).length} news, crypto=${!!market.crypto}`);
    } catch (e) { console.error('[market] fetchMarketData crashed:', e.message); }
    
    // Build market overview from REAL data only (no LLM call = no OOM risk)
    const si = market.stockIndices || {};
    const fmtIdx = (idx) => idx ? `${idx.name || ''} ${idx.price} (${idx.change>0?'+':''}${idx.change}%)` : '';
    
    const marketOverview = {
      stocks: {
        us: (si.nasdaq || si.dji) ? `${si.nasdaq ? fmtIdx(si.nasdaq) : ''}${si.dji ? ' | ' + fmtIdx(si.dji) : ''}` : null,
        cn: (si.sse || si.szse) ? `${si.sse ? fmtIdx(si.sse) : ''}${si.szse ? ' | ' + fmtIdx(si.szse) : ''}` : null,
        hk: si.hsi ? fmtIdx(si.hsi) : null,
        crypto: market.crypto ? `BTC $${market.crypto.btc?.price?.toLocaleString()} (${market.crypto.btc?.change>0?'+':''}${market.crypto.btc?.change}%) | ETH $${market.crypto.eth?.price?.toLocaleString()} (${market.crypto.eth?.change>0?'+':''}${market.crypto.eth?.change}%)` : null,
      },
      stockSources: {
        us: (si.nasdaq || si.dji) ? 'æ–°æµªè´¢ç» (å®žæ—¶)' : null,
        cn: (si.sse || si.szse) ? 'æ–°æµªè´¢ç» (å®žæ—¶)' : null,
        hk: si.hsi ? 'æ–°æµªè´¢ç» (å®žæ—¶)' : null,
        crypto: 'CoinGecko (å®žæ—¶)',
      },
      stockIndices: si,
      summary: null, // No LLM summary to save memory
      news: (market.news || []).slice(0, 10),
      bigNews: [], // Raw news replaces LLM-analyzed news
      events: [],
      crypto: market.crypto,
      fearGreed: market.fearGreed,
      lastUpdate: new Date().toISOString(),
    };
    
    // Save market snapshot
    try {
      await pool.execute(
        'INSERT INTO market_snapshots (snapshot_date, data) VALUES (?, ?) ON DUPLICATE KEY UPDATE data=VALUES(data)',
        [today, JSON.stringify(marketOverview)]
      );
    } catch {}
    
    status.progress = 80;
    status.message = 'ðŸš€ ç”Ÿæˆé™æ€æ–‡ä»¶...';
    
    // 6. Build latest.json
    // Get recent opportunities (last 3 days) for cumulative view
    const [recentOpps] = await pool.execute(
      'SELECT data, feasibility, created_date FROM opportunities WHERE created_date >= DATE_SUB(CURDATE(), INTERVAL 3 DAY) ORDER BY feasibility ASC, created_date DESC LIMIT 30'
    );
    
    const allOpps = recentOpps.map(r => {
      const d = typeof r.data === 'string' ? JSON.parse(r.data) : r.data;
      d._fromPrevious = r.created_date.toISOString().split('T')[0] !== today;
      return d;
    });
    
    const latestJson = {
      status: 'done',
      generatedAt: new Date().toISOString(),
      marketOverview,
      rawCount: items.length,
      sourceCounts: {
        HackerNews: items.filter(i => i._source === 'hn').length,
        AskHN: items.filter(i => i._source === 'ask_hn').length,
        GitHub: items.filter(i => i._source === 'github').length,
        GitHubIssues: items.filter(i => i._source === 'github_issues').length,
        StackOverflow: items.filter(i => i._source === 'stackoverflow').length,
        Reddit: items.filter(i => i._source === 'reddit').length,
      },
      painSignalCount: items.filter(i => (i._painSignals || []).length > 0).length,
      opportunities: allOpps,
      summary: `å…± ${allOpps.length} ä¸ªå•†æœºï¼ˆä»Šæ—¥æ–°å¢ž ${opportunities.length} ä¸ªï¼‰`,
    };
    
    // 7. Write latest.json to public web dir (auto-deployed via junaitools.com)
    const fs = require('fs');
    const homeDir = process.env.HOME || '/home/ztshkzhkyl';
    const webDataDir = `${homeDir}/junaitools.com/painradar/data`;
    fs.mkdirSync(webDataDir, { recursive: true });
    fs.writeFileSync(`${webDataDir}/latest.json`, JSON.stringify(latestJson));
    // Also keep local copy
    fs.writeFileSync('/tmp/painradar-latest.json', JSON.stringify(latestJson));
    console.log(`[deploy] latest.json auto-published (${allOpps.length} opps)`);
    
    status.progress = 100;
    status.state = 'done';
    status.message = `âœ… ${opportunities.length} ä¸ªæ–°å•†æœºå·²ç”Ÿæˆ`;
    status.result = latestJson;
    console.log(`=== Done! ${opportunities.length} new opportunities ===`);
    
  } catch (err) {
    console.error('[run] Error:', err);
    status = { state: 'error', progress: 0, message: `âŒ ${err.message}` };
  }
}

// ========== HTTP Server ==========
const server = http.createServer(async (req, res) => {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
  res.setHeader('Content-Type', 'application/json; charset=utf-8');
  
  const send = (code, body) => { res.writeHead(code); res.end(JSON.stringify(body)); };
  if (req.method === 'OPTIONS') return send(200, {});
  
  const url = new URL(req.url, `http://localhost:${PORT}`);
  
  if (url.pathname === '/status') return send(200, status);
  
  if (url.pathname === '/trigger' && (req.method === 'POST' || url.searchParams.get('action') === 'trigger')) {
    if (status.state === 'running') return send(200, { status: 'already_running' });
    runFullAnalysis();
    return send(200, { status: 'triggered' });
  }
  
  if (url.pathname === '/result') {
    if (status.result) return send(200, status.result);
    return send(404, { error: 'No result yet' });
  }
  
  if (url.pathname === '/market') {
    try {
      const [rows] = await pool.execute('SELECT data FROM market_snapshots ORDER BY snapshot_date DESC LIMIT 1');
      if (rows.length) return send(200, typeof rows[0].data === 'string' ? JSON.parse(rows[0].data) : rows[0].data);
    } catch {}
    return send(404, { error: 'No market data' });
  }
  
  if (url.pathname === '/opportunities') {
    try {
      const days = parseInt(url.searchParams.get('days') || '7');
      const [rows] = await pool.execute(
        'SELECT data, feasibility, created_date FROM opportunities WHERE created_date >= DATE_SUB(CURDATE(), INTERVAL ? DAY) ORDER BY feasibility ASC, created_date DESC',
        [days]
      );
      return send(200, rows.map(r => typeof r.data === 'string' ? JSON.parse(r.data) : r.data));
    } catch (e) { return send(500, { error: e.message }); }
  }
  
  // === Async Analysis APIs (GET-based to avoid WAF 403 on shared hosting) ===
  
  // GET /analyze/market â€” è§¦å‘å¸‚åœºåˆ†æž (GET to avoid WAF)
  if (url.pathname === '/analyze/market' && url.searchParams.get('action') === 'trigger') {
    try {
      const market = await fetchMarketData();
      const taskId = await createTask('market', {
        stockIndices: market.stockIndices,
        crypto: market.crypto,
        fearGreed: market.fearGreed,
        news: (market.news || []).slice(0, 8),
      });
      runMarketAnalysis(taskId);
      return send(200, { taskId, state: 'pending' });
    } catch (e) { return send(500, { error: e.message }); }
  }
  
  // GET /analyze/news â€” è§¦å‘æ–°é—»åˆ†æž (GET to avoid WAF)
  if (url.pathname === '/analyze/news' && url.searchParams.get('action') === 'trigger') {
    try {
      const market = await fetchMarketData();
      const taskId = await createTask('news', { news: (market.news || []).slice(0, 10) });
      runNewsAnalysis(taskId);
      return send(200, { taskId, state: 'pending' });
    } catch (e) { return send(500, { error: e.message }); }
  }
  
  // GET /analyze/:id â€” æŸ¥è¯¢åˆ†æžä»»åŠ¡çŠ¶æ€/ç»“æžœ
  if (req.method === 'GET' && url.pathname.startsWith('/analyze/')) {
    const taskId = url.pathname.split('/')[2];
    if (!taskId) return send(400, { error: 'task id required' });
    try {
      const [rows] = await pool.execute('SELECT * FROM analysis_tasks WHERE id=?', [taskId]);
      if (!rows.length) return send(404, { error: 'Task not found' });
      const task = rows[0];
      return send(200, {
        taskId: task.id,
        type: task.type,
        state: task.state,
        result: task.result ? (typeof task.result === 'string' ? JSON.parse(task.result) : task.result) : null,
        error: task.error_msg,
        createdAt: task.created_at,
        completedAt: task.completed_at,
      });
    } catch (e) { return send(500, { error: e.message }); }
  }
  
  // GET /analyze â€” åˆ—å‡ºæœ€è¿‘çš„åˆ†æžä»»åŠ¡
  if (req.method === 'GET' && url.pathname === '/analyze') {
    try {
      const type = url.searchParams.get('type');
      const limit = parseInt(url.searchParams.get('limit')) || 10;
      let sql = 'SELECT id, type, state, created_at, completed_at FROM analysis_tasks';
      const params = [];
      if (type) { sql += ' WHERE type=?'; params.push(type); }
      sql += ' ORDER BY created_at DESC LIMIT ?';
      params.push(limit);
      const [rows] = await pool.execute(sql, params);
      return send(200, { tasks: rows });
    } catch (e) { return send(500, { error: e.message }); }
  }
  
  // Deep search
  if (req.method === 'POST' && url.pathname === '/search') {
    let body = '';
    req.on('data', c => body += c);
    req.on('end', async () => {
      try {
        const { keyword } = JSON.parse(body);
        if (!keyword) return send(400, { error: 'keyword required' });
        
        // Fetch HN + GitHub for this keyword
        const [hnRes, ghRes] = await Promise.allSettled([
          fetchHNQuery(keyword, 15),
          fetchGH(`${keyword} type:issue sort:reactions`, 10),
        ]);
        const hn = hnRes.status === 'fulfilled' ? hnRes.value : [];
        const gh = ghRes.status === 'fulfilled' ? ghRes.value : [];
        
        const items = [...hn, ...gh].slice(0, 15);
        const itemList = items.map((i, idx) => `${idx+1}. [${i._source}] ${i.title} | ${i.points || i.reactions || 0}`).join('\n');
        
        const prompt = `ä½ æ˜¯ä¸€ä½ç‹¬ç«‹å¼€å‘è€…å•†æœºåˆ†æžå¸ˆã€‚é’ˆå¯¹"${keyword}"è¿™ä¸ªé¢†åŸŸï¼Œç»“åˆä»¥ä¸‹ç¤¾åŒºè®¨è®ºæ•°æ®ï¼Œè¾“å‡ºä¸€ä»½æ·±åº¦å•†æœºåˆ†æžæŠ¥å‘Šã€‚

ç¤¾åŒºæ•°æ®ï¼š
${itemList}

è¦æ±‚ï¼ˆä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONç»“æž„è¾“å‡ºï¼‰ï¼š

1. executive_summaryï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šç”¨3-5å¥è¯æ€»ç»“è¯¥é¢†åŸŸçš„å•†ä¸šæ½œåŠ›ï¼ŒåŒ…å«å¸‚åœºè§„æ¨¡ä¼°ç®—ã€å¢žé•¿è¶‹åŠ¿ã€å…³é”®é©±åŠ¨åŠ›ã€‚å¿…é¡»å…·ä½“ï¼Œä¸è¦ç©ºè¯ã€‚

2. existing_productsï¼ˆæ•°ç»„ï¼Œè‡³å°‘3ä¸ªï¼‰ï¼šè¯¥é¢†åŸŸå·²æœ‰çš„çŸ¥åäº§å“/æœåŠ¡ï¼Œæ¯ä¸ªåŒ…å«ï¼š
   - nameï¼šäº§å“åç§°ï¼ˆå¦‚ "Snyk", "SonarQube"ï¼‰
   - websiteï¼šå®˜ç½‘URL
   - what_it_doesï¼šè¿™ä¸ªäº§å“æ˜¯å¹²ä»€ä¹ˆçš„ï¼ˆ2-3å¥è¯ï¼Œé€šä¿—æ˜“æ‡‚ï¼‰
   - pricingï¼šå®šä»·æ¨¡å¼ï¼ˆå…è´¹/ä»˜è´¹/Freemiumï¼Œå…·ä½“ä»·æ ¼ï¼‰
   - strengthsï¼šæ ¸å¿ƒä¼˜åŠ¿ï¼ˆ1-2å¥è¯ï¼‰
   - weaknessesï¼šä¸»è¦ä¸è¶³/ç”¨æˆ·åæ§½ç‚¹ï¼ˆ1-2å¥è¯ï¼‰
   - target_usersï¼šç›®æ ‡ç”¨æˆ·ç¾¤

3. painPointsï¼ˆæ•°ç»„ï¼Œè‡³å°‘4ä¸ªï¼‰ï¼šæ¯ä¸ªç—›ç‚¹åŒ…å«ï¼š
   - titleï¼šç—›ç‚¹æ ‡é¢˜
   - descriptionï¼šå…·ä½“æè¿°ï¼ˆå¼•ç”¨ç¤¾åŒºè®¨è®ºä¸­çš„çœŸå®žè¯æ®ï¼Œè‡³å°‘50å­—ï¼‰
   - severityï¼šhigh/medium/low
   - willingness_to_payï¼šç”¨æˆ·ä¸ºè§£å†³æ­¤ç—›ç‚¹æ„¿æ„æ”¯ä»˜å¤šå°‘ï¼ˆå…·ä½“é‡‘é¢èŒƒå›´ï¼‰
   - affected_usersï¼šå—å½±å“çš„ç”¨æˆ·ç¾¤ä½“å’Œä¼°è®¡è§„æ¨¡
   - current_solutionsï¼šçŽ°æœ‰è§£å†³æ–¹æ¡ˆåŠå…¶ä¸è¶³

4. opportunitiesï¼ˆæ•°ç»„ï¼Œè‡³å°‘3ä¸ªï¼‰ï¼šæ¯ä¸ªå•†æœºåŒ…å«ï¼š
   - titleï¼šäº§å“åç§°
   - descriptionï¼šäº§å“å®šä½ï¼ˆ2-3å¥è¯ï¼‰
   - related_productsï¼šä¸Žå“ªäº›å·²æœ‰äº§å“ç›¸å…³/ç«žäº‰ï¼ˆåˆ—å‡ºåç§°ï¼‰
   - our_advantageï¼šæˆ‘ä»¬ä½œä¸ºç‹¬ç«‹å¼€å‘è€…çš„å·®å¼‚åŒ–ä¼˜åŠ¿åœ¨å“ªé‡Œï¼ˆä¸ºä»€ä¹ˆç”¨æˆ·ä¼šé€‰æˆ‘ä»¬è€Œä¸æ˜¯å·²æœ‰äº§å“ï¼Œè‡³å°‘2å¥è¯ï¼‰
   - monetizationï¼šå…·ä½“å®šä»·ç­–ç•¥ï¼ˆæœˆè´¹/å¹´è´¹/ä¸€æ¬¡æ€§ï¼Œå…·ä½“é‡‘é¢ï¼‰
   - dev_costï¼šå¼€å‘æˆæœ¬ä¼°ç®—ï¼ˆäººæ•°Ã—æ—¶é—´ï¼‰
   - competitionï¼šä¸»è¦ç«žå“è¯¦ç»†åˆ†æžï¼ˆè‡³å°‘2ä¸ªç«žå“ï¼Œè¯´æ˜Žå„è‡ªä¼˜åŠ£åŠ¿ï¼‰
   - first_stepï¼šç‹¬ç«‹å¼€å‘è€…ç¬¬ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼ˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨ï¼‰
   - revenue_potentialï¼š12ä¸ªæœˆå†…çš„æ”¶å…¥é¢„æœŸ

5. market_contextï¼š
   - market_sizeï¼šé¢„ä¼°å¸‚åœºè§„æ¨¡
   - growth_rateï¼šå¢žé•¿çŽ‡
   - key_playersï¼šä¸»è¦çŽ©å®¶
   - entry_barriersï¼šè¿›å…¥å£åž’

6. verdictï¼š
   - scoreï¼š1-10è¯„åˆ†
   - recommendationï¼šç»™ç‹¬ç«‹å¼€å‘è€…çš„å…·ä½“å»ºè®®ï¼ˆè‡³å°‘3å¥è¯ï¼ŒåŒ…å«å…·ä½“è¡ŒåŠ¨æ­¥éª¤ï¼‰
   - risk_factorsï¼šä¸»è¦é£Žé™©ç‚¹ï¼ˆè‡³å°‘2ä¸ªï¼‰

è¾“å‡ºçº¯JSONï¼Œä¸è¦markdownã€‚ä¸­æ–‡ã€‚æ¯ä¸ªå­—æ®µéƒ½è¦æœ‰å®žè´¨å†…å®¹ï¼Œä¸è¦æ³›æ³›è€Œè°ˆã€‚`;
        
        const result = await callLLM(prompt, 15000); // GLM-5 needs more tokens (thinking + output)
        const report = tryParseJSON(result);
        const finalReport = report || { executive_summary: result.substring(0, 500) };
        
        // Save to MySQL
        try {
          const score = finalReport.verdict?.score || null;
          await pool.execute(
            'INSERT INTO search_reports (keyword, report, raw_count, score) VALUES (?, ?, ?, ?)',
            [keyword, JSON.stringify(finalReport), items.length, score]
          );
          console.log(`[search] Saved report for "${keyword}" (score: ${score})`);
        } catch (dbErr) { console.error('[search] DB save failed:', dbErr.message); }
        
        send(200, { keyword, report: finalReport, rawCount: items.length });
      } catch (e) { send(500, { error: e.message }); }
    });
    return;
  }
  
  // GET /reports â€” èŽ·å–åŽ†å²æœç´¢æŠ¥å‘Šåˆ—è¡¨
  if (req.method === 'GET' && url.pathname === '/reports') {
    try {
      const limit = parseInt(url.searchParams.get('limit')) || 20;
      const [rows] = await pool.execute(
        'SELECT id, keyword, score, raw_count, created_at FROM search_reports ORDER BY created_at DESC LIMIT ?',
        [limit]
      );
      send(200, { reports: rows });
    } catch (e) { send(500, { error: e.message }); }
    return;
  }

  // GET /reports/:id â€” èŽ·å–å•ä¸ªæŠ¥å‘Šè¯¦æƒ…
  if (req.method === 'GET' && url.pathname.startsWith('/reports/')) {
    try {
      const id = url.pathname.split('/')[2];
      const [rows] = await pool.execute('SELECT * FROM search_reports WHERE id = ?', [id]);
      if (rows.length === 0) return send(404, { error: 'Report not found' });
      const row = rows[0];
      row.report = typeof row.report === 'string' ? JSON.parse(row.report) : row.report;
      send(200, { keyword: row.keyword, report: row.report, rawCount: row.raw_count, createdAt: row.created_at });
    } catch (e) { send(500, { error: e.message }); }
    return;
  }

  send(200, { service: 'PainRadar Backend', status: status.state, endpoints: ['/status', '/trigger', '/result', '/market', '/opportunities', '/search', '/reports'] });
});

// ========== Start ==========
(async () => {
  await initDB();
  server.listen(PORT, '0.0.0.0', () => {
    console.log(`\nðŸ” PainRadar Backend | http://0.0.0.0:${PORT}`);
    console.log(`   GET  /status        â†’ æŸ¥è¯¢çŠ¶æ€`);
    console.log(`   POST /trigger       â†’ è§¦å‘åˆ†æž`);
    console.log(`   GET  /result        â†’ æœ€æ–°ç»“æžœ`);
    console.log(`   GET  /market        â†’ å¸‚åœºæ•°æ®`);
    console.log(`   GET  /opportunities â†’ åŽ†å²å•†æœº`);
    console.log(`   POST /search        â†’ æ·±åº¦æœç´¢\n`);
  });
})();
